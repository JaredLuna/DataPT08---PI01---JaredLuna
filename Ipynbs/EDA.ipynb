{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "En este archivo nos centraremos en analizar nuestros datos, revisar los datasets proporcionados y tratar de decifrar que contienen y que acciones tomar para poder mejorar nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerias con las que vamos a trabajar solamente\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comenzar podemos observar que nuestros datos se encuentra en un archivo formato\n",
    ".json tipo diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La información de nuestro dataframe de SteamGames:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120445 entries, 0 to 120444\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   publisher     24083 non-null  object \n",
      " 1   genres        28852 non-null  object \n",
      " 2   app_name      32133 non-null  object \n",
      " 3   title         30085 non-null  object \n",
      " 4   url           32135 non-null  object \n",
      " 5   release_date  30068 non-null  object \n",
      " 6   tags          31972 non-null  object \n",
      " 7   reviews_url   32133 non-null  object \n",
      " 8   specs         31465 non-null  object \n",
      " 9   price         30758 non-null  object \n",
      " 10  early_access  32135 non-null  float64\n",
      " 11  id            32133 non-null  float64\n",
      " 12  developer     28836 non-null  object \n",
      "dtypes: float64(2), object(11)\n",
      "memory usage: 11.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#Importamos con pandas nuestros archivos json\n",
    "df_steamGames = pd.read_json(r'..\\DataRaw\\\\output_steam_games.json', lines= True)\n",
    "\n",
    "print(f'La información de nuestro dataframe de SteamGames:\\n')\n",
    "df_steamGames.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada columna tiene más de 120k entradas y de la información de nuestro df, se puede observar\n",
    "que aproximadamente solo el 25% de nuestro df tiene datos, unas columnas tienen más datos que otras\n",
    "pero rondan casi por los mismos valores. Aquí enfrentamos un problema grande, si se opta por eliminar\n",
    "todos los datos vacios perderiamos mucha información que en caso de querer hacer un estudio\n",
    "muy profundo realmente nos veríamos muy afectado. Sin embargo, en este proyecto no es necesario\n",
    "tener una información tan detallada o no es de gran relevancia, por eso vamos a trabajar solo con \n",
    "las filas que contengan los datos completos o la mayoría de los mismo.\n",
    "\n",
    "Entonces en nuestra ETL del df de juegos steam y los demas datsets vamos a eliminar los valores vacios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8240\n"
     ]
    }
   ],
   "source": [
    "#Ahora vamos a revisar si existen valores repetidos\n",
    "repets = df_steamGames['publisher'].unique()\n",
    "print(len(repets))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que solo para publisher de tener más de 24k datos, al final solo\n",
    "tenemos 8k diferentes, por lo tanto sabemos que hay publishers repetidos, sin embargo eso es posible\n",
    "ya que un publisher puede tener varios juegos diferentes.\n",
    "\n",
    "\n",
    "Ahora empezamos a trabajar con los otros dos datasets.\n",
    "\n",
    "Para el data set de australian items tenemos que utilizar otro estilo de decodificación, ya que\n",
    "de otra manera tendremos errores leyendo el archivo con pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>items_count</th>\n",
       "      <th>steam_id</th>\n",
       "      <th>user_url</th>\n",
       "      <th>items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>277</td>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>http://steamcommunity.com/profiles/76561197970...</td>\n",
       "      <td>[{'item_id': '10', 'item_name': 'Counter-Strik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>js41637</td>\n",
       "      <td>888</td>\n",
       "      <td>76561198035864385</td>\n",
       "      <td>http://steamcommunity.com/id/js41637</td>\n",
       "      <td>[{'item_id': '10', 'item_name': 'Counter-Strik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evcentric</td>\n",
       "      <td>137</td>\n",
       "      <td>76561198007712555</td>\n",
       "      <td>http://steamcommunity.com/id/evcentric</td>\n",
       "      <td>[{'item_id': '1200', 'item_name': 'Red Orchest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Riot-Punch</td>\n",
       "      <td>328</td>\n",
       "      <td>76561197963445855</td>\n",
       "      <td>http://steamcommunity.com/id/Riot-Punch</td>\n",
       "      <td>[{'item_id': '10', 'item_name': 'Counter-Strik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doctr</td>\n",
       "      <td>541</td>\n",
       "      <td>76561198002099482</td>\n",
       "      <td>http://steamcommunity.com/id/doctr</td>\n",
       "      <td>[{'item_id': '300', 'item_name': 'Day of Defea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id  items_count           steam_id  \\\n",
       "0  76561197970982479          277  76561197970982479   \n",
       "1            js41637          888  76561198035864385   \n",
       "2          evcentric          137  76561198007712555   \n",
       "3         Riot-Punch          328  76561197963445855   \n",
       "4              doctr          541  76561198002099482   \n",
       "\n",
       "                                            user_url  \\\n",
       "0  http://steamcommunity.com/profiles/76561197970...   \n",
       "1               http://steamcommunity.com/id/js41637   \n",
       "2             http://steamcommunity.com/id/evcentric   \n",
       "3            http://steamcommunity.com/id/Riot-Punch   \n",
       "4                 http://steamcommunity.com/id/doctr   \n",
       "\n",
       "                                               items  \n",
       "0  [{'item_id': '10', 'item_name': 'Counter-Strik...  \n",
       "1  [{'item_id': '10', 'item_name': 'Counter-Strik...  \n",
       "2  [{'item_id': '1200', 'item_name': 'Red Orchest...  \n",
       "3  [{'item_id': '10', 'item_name': 'Counter-Strik...  \n",
       "4  [{'item_id': '300', 'item_name': 'Day of Defea...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Leemos el archivo linea por linea para poder decodificar\n",
    "rows = []\n",
    "\n",
    "with open(r'..\\DataRaw\\\\australian_users_items.json', encoding= 'MacRoman') as f:\n",
    "    for line in f.readlines():\n",
    "        rows.append(ast.literal_eval(line))\n",
    "\n",
    "f.close()\n",
    "    \n",
    "df_australian_items = pd.DataFrame(rows)\n",
    "df_australian_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar en la última columna tenemos información anidada, así que tenemos que en la ETL\n",
    "vamos a tener que desanidar esa columna para poder generar un dataframe con toda la información\n",
    "por columnas separadas. Tambien podemos ver el tiempo de ejecución, en este caso fue bastante, esto nos\n",
    "indica que el dataset es muy pesado y tenemos que optimizar este formato de lectura en la ETL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 88310 entries, 0 to 88309\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   user_id      88310 non-null  object\n",
      " 1   items_count  88310 non-null  int64 \n",
      " 2   steam_id     88310 non-null  object\n",
      " 3   user_url     88310 non-null  object\n",
      " 4   items        88310 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Analizando la cantidad de datos vacios en este ultimo dataframe\n",
    "df_australian_items.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este dataset podemos ver que tenemos 88310 entradas. En este dataframe tenemos\n",
    "todos los datos completos, por lo cual en la ETL solo va a ser necesario desanidar\n",
    "la información de la columna de items para poder expandir este dataframe\n",
    "\n",
    "\n",
    "Ahora procedemos con el tercer dataset, el user reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_url</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197970982479</td>\n",
       "      <td>http://steamcommunity.com/profiles/76561197970...</td>\n",
       "      <td>[{'funny': '', 'posted': 'Posted November 5, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>js41637</td>\n",
       "      <td>http://steamcommunity.com/id/js41637</td>\n",
       "      <td>[{'funny': '', 'posted': 'Posted June 24, 2014...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evcentric</td>\n",
       "      <td>http://steamcommunity.com/id/evcentric</td>\n",
       "      <td>[{'funny': '', 'posted': 'Posted February 3.',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doctr</td>\n",
       "      <td>http://steamcommunity.com/id/doctr</td>\n",
       "      <td>[{'funny': '', 'posted': 'Posted October 14, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maplemage</td>\n",
       "      <td>http://steamcommunity.com/id/maplemage</td>\n",
       "      <td>[{'funny': '3 people found this review funny',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id                                           user_url  \\\n",
       "0  76561197970982479  http://steamcommunity.com/profiles/76561197970...   \n",
       "1            js41637               http://steamcommunity.com/id/js41637   \n",
       "2          evcentric             http://steamcommunity.com/id/evcentric   \n",
       "3              doctr                 http://steamcommunity.com/id/doctr   \n",
       "4          maplemage             http://steamcommunity.com/id/maplemage   \n",
       "\n",
       "                                             reviews  \n",
       "0  [{'funny': '', 'posted': 'Posted November 5, 2...  \n",
       "1  [{'funny': '', 'posted': 'Posted June 24, 2014...  \n",
       "2  [{'funny': '', 'posted': 'Posted February 3.',...  \n",
       "3  [{'funny': '', 'posted': 'Posted October 14, 2...  \n",
       "4  [{'funny': '3 people found this review funny',...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tenemos el mismo problema que con el dataset pasado, así que utilizaremos la misma decodificación\n",
    "rows = []\n",
    "\n",
    "with open(r'..\\DataRaw\\\\australian_user_reviews.json', encoding= 'MacRoman') as f:\n",
    "    for line in f.readlines():\n",
    "        rows.append(ast.literal_eval(line))\n",
    "\n",
    "f.close()\n",
    "    \n",
    "df_aust_reviews = pd.DataFrame(rows)\n",
    "df_aust_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este data set podemos observar que el tiempo de procesamiento fue mucho menor, sin embargo,\n",
    "tenemos otra columna con información anidada, así que vamos a tener que desanidar también para la ETL\n",
    "de este data set.\n",
    "\n",
    "Ahora, viendo los valores vacios..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25799 entries, 0 to 25798\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   user_id   25799 non-null  object\n",
      " 1   user_url  25799 non-null  object\n",
      " 2   reviews   25799 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 604.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_aust_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que en este dataset contamos con la información completa, de las 25799 entradas\n",
    "tenemos el mismo numero de entradas NO nulas, por lo tanto no va a ser necesario eliminar datos vacios\n",
    "lo más importante va a ser el desanidar la columna \"reviews\", que será de donde encontremos nuestras\n",
    "recomendaciones con el MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **--- RECAPITULANDO ---**\n",
    "\n",
    "1._ Para el dataset de steam games es necesario eliminar todos los datos vaciós y podemos ordenar\n",
    "los alfabeticamente los publishers para mayor orden\n",
    "\n",
    "2._ Para el australian items es necesario desanidar la columna de items y así expandir nuestro dataframe\n",
    "\n",
    "3._ Para el australian reviews es necesario hacer lo mismo, desanidar la columna de reviews y así expandir\n",
    "el dataframe para tener más datos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
